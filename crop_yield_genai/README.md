# Crop Yield Prediction â€” Prototype B (GenAIâ€‘Assisted)

A **GenAIâ€‘assisted** baseline for predicting crop yield (kg/ha). This prototype keeps the same supervised
learning pipeline as the traditional version but uses **generative AI** to accelerate:
- **Feature ideas** (adds `GDD_approx` â€” a simple growingâ€‘degree proxy)
- **Hyperparameter search** (compact, smallâ€‘data friendly **RandomForest** grid via GridSearchCV)
- **EDA narration & docs** (short draft text captured in `outputs/eda_narrative_genai.md` and `prompts_log.md`)

No external GenAI APIs are called at runtime; GenAI contributions are embedded in the repository and curated by you.

---

## ğŸ“ Folder Structure (expected)

```
crop_yield_genai/
â”œâ”€ data/
â”‚  â””â”€ crop_yield_sample.csv            # your dataset
â”œâ”€ notebooks/
â”‚  â”œâ”€ 03_genai_assisted.ipynb          # main GenAIâ€‘assisted build
â”‚  â””â”€ 04_eval_compare.ipynb            # optional: compare vs Noâ€‘GenAI models
â”œâ”€ outputs/
â”‚  â”œâ”€ figures/                         # autoâ€‘saved plots
â”‚  â”œâ”€ models/                          # autoâ€‘saved best model (genai_rf.pkl)
â”‚  â””â”€ eda_narrative_genai.md           # draft EDA notes (editable)
â”œâ”€ src/
â”‚  â”œâ”€ data_preprocessing.py            # includes add_gdd_feature()
â”‚  â”œâ”€ model.py                         # suggested_rf_grid() + GridSearchCV
â”‚  â””â”€ visualization.py
â”œâ”€ app.py                               # optional Streamlit demo
â”œâ”€ prompts_log.md                       # selected prompts for transparency
â”œâ”€ README.md                            # this file
â”œâ”€ requirements.txt
â””â”€ .gitignore
```

> If folders are missing, create them. The notebooks will create `outputs/` automatically.

---

## ğŸš€ Quick Start

### 1) Create & activate a virtual environment
```bash
python -m venv .venv
# Windows
.venv\Scripts\activate
# macOS/Linux
source .venv/bin/activate
```

### 2) Install dependencies
```bash
pip install -r requirements.txt
```

### 3) Add your data
Place a CSV at: `data/crop_yield_sample.csv` with at least these columns:

| Column          | Type  | Description                              |
|-----------------|-------|------------------------------------------|
| Year            | int   | Crop season year                         |
| Region          | str   | Region identifier (e.g., R1, R2, â€¦)      |
| Crop            | str   | Crop type (e.g., Wheat, Maize)           |
| Rainfall_mm     | float | Seasonal cumulative rainfall             |
| Temperature_C   | float | Seasonal mean temperature                |
| Fertilizer_kg   | float | Fertilizer rate (kg/ha)                  |
| Yield_kg_ha     | float | **Target**: observed yield (kg/ha)       |

> The GenAIâ€‘assisted pipeline will also compute **`GDD_approx = max(0, Temperature_C âˆ’ 10) Ã— 120`**.

### 4) Train the GenAIâ€‘assisted model
Open and **run all cells** in:
```
notebooks/03_genai_assisted.ipynb
```
This will:
- Load & clean data, **add `GDD_approx`**, and encode categoricals
- Perform a **timeâ€‘based split** (last 2 years used for test)
- Train: Linear Regression (reference) + **RandomForest with a compact RF grid** via GridSearchCV
- Save plots to `outputs/figures/`, a short **EDA narrative** to `outputs/eda_narrative_genai.md`,
  and the selected model to `outputs/models/genai_rf.pkl`

### 5) (Optional) Compare with your Noâ€‘GenAI prototype
After you have models from both prototypes saved in `outputs/models/`, open:
```
notebooks/04_eval_compare.ipynb
```
It will load any available models (baseline LR/RF, GenAI RF) and report **MAE / RMSE / RÂ²** on the same test split.

### 6) (Optional) Demo app
```bash
streamlit run app.py
```
- Choose `genai_rf.pkl` (or other available models)
- Enter rainfall, temperature, fertilizer, region, crop â†’ get predicted yield

---

## ğŸ§  What is â€œGenAIâ€‘assistedâ€ here?

- **Feature idea**: `GDD_approx` based on mean seasonal temperature (no external calls)
- **Hyperparameters**: a **small** grid tuned for â‰¤500 rows to speed up search
- **Narration**: draft EDA text and docstring polish (you review & edit)
- **Transparency**: `prompts_log.md` keeps a record of prompts used

**Guardrails**
- Verify all code & metrics manually
- Donâ€™t evaluate on synthetic data
- Keep heldâ€‘out test data truly unseen

---

## ğŸ“Š Metrics & Model Selection

We report **MAE**, **RMSE**, and **RÂ²** on the heldâ€‘out test set.  
The notebook selects the **lowest RMSE** model and saves it to `outputs/models/genai_rf.pkl`.

---

## ğŸ§° Troubleshooting

- **No model found in app** â†’ Run the notebook first to save one.
- **Feature mismatch** â†’ Ensure the appâ€™s inputs match training features; retrain & save again if you changed features.
- **Slow grid search** â†’ Reduce `n_estimators` options or folds in `GridSearchCV`.

---

## âœ… Deliverables Checklist

- [ ] Executed `03_genai_assisted.ipynb` with results
- [ ] `outputs/models/genai_rf.pkl` saved
- [ ] `outputs/figures/*` + `outputs/eda_narrative_genai.md`
- [ ] `prompts_log.md` updated
- [ ] (Optional) `04_eval_compare.ipynb` run & screenshot
- [ ] (Optional) Streamlit demo screenshot

---

## ğŸ“ Notes & Next Steps

- Consider adding soil/NDVI features and trying gradient boosting (XGBoost/LightGBM).
- Add model explainability (e.g., SHAP) and partial dependence plots.
- Track **time saved** and **iteration count** vs. the Noâ€‘GenAI prototype for your report.
